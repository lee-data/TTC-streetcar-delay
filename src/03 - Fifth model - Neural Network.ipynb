{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "\n",
    "# **PREDICTIVE METHOD**<br>\n",
    "# **NEURAL NETWORK**<br>\n",
    "\n",
    "by: Ly Nguyen\n",
    "\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries for this notebook: \n",
    "\n",
    "# Read from SQLite database and load to a pandas dataframe\n",
    "import os\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# For using arrays \n",
    "import numpy as np\n",
    "\n",
    "# For ML work (data preprocessing, hyperparameter tuning, Random Forest Classifier, training & testing sets, and stratified sampling)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "\n",
    "\n",
    "# For model evaluation, including explainability:  \n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import classification_report, balanced_accuracy_score, make_scorer\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import statsmodels.api as sm\n",
    "import shap\n",
    "\n",
    "# For data visualization \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# For saving the model into a pkl file\n",
    "import joblib\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Set seed for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved df_prelim parquet file: \n",
    "relative_path = os.path.join(\"..\", \"src\", \"df_reduced.parquet\")\n",
    "df_reduced = pd.read_parquet(relative_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split training & test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X and y:\n",
    "X = df_reduced.drop(columns=['delayType'])  # Use parentheses with the 'columns' argument\n",
    "y = df_reduced['delayType']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform stratified split\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode the target for neural network\n",
    "y_train_encoded = to_categorical(y_train - 1)  # Zero-indexed for NN\n",
    "y_val_encoded = to_categorical(y_val - 1)\n",
    "y_test_encoded = to_categorical(y_test - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: {0: 3.1258878275777615, 1: 0.4759294477383749, 2: 1.7272973338746787}\n"
     ]
    }
   ],
   "source": [
    "# Compute class weights\n",
    "class_weights = compute_class_weight(class_weight='balanced',\n",
    "                                     classes=np.unique(y_train),\n",
    "                                     y=y_train)\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "print(\"Class weights:\", class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hp.Int('units', min_value=64, max_value=256, step=64),\n",
    "                    activation='relu', input_shape=(X_train.shape[1],)))\n",
    "    model.add(Dropout(hp.Float('dropout', 0.1, 0.5, step=0.1)))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    model.compile(optimizer=Adam(learning_rate=hp.Choice('learning_rate', [0.001, 0.0001])),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from .\\untitled_project\\tuner0.json\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.Hyperband(build_model, \n",
    "                     objective='val_accuracy', \n",
    "                     max_epochs=30, \n",
    "                     factor=3)\n",
    "\n",
    "# Hyperparameter search\n",
    "tuner.search(X_train, y_train_encoded, \n",
    "             validation_data=(X_val, y_val_encoded), \n",
    "             class_weight=class_weights)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'units': 256, 'dropout': 0.2, 'learning_rate': 0.001, 'tuner/epochs': 10, 'tuner/initial_epoch': 0, 'tuner/bracket': 0, 'tuner/round': 0}\n"
     ]
    }
   ],
   "source": [
    "# Display the best hyperparameters \n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(best_hps.values)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 256)               13056     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                16448     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29,699\n",
      "Trainable params: 29,699\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Print the best model's architecture \n",
    "best_model = tuner.hypermodel.build(best_hps)\n",
    "best_model.summary()  # This will print the architecture\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "399/399 [==============================] - 2s 3ms/step - loss: 0.9167 - accuracy: 0.4911 - val_loss: 1.0241 - val_accuracy: 0.4654\n",
      "Epoch 2/30\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.8365 - accuracy: 0.5540 - val_loss: 0.9022 - val_accuracy: 0.5580\n",
      "Epoch 3/30\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.8045 - accuracy: 0.5755 - val_loss: 0.8928 - val_accuracy: 0.5707\n",
      "Epoch 4/30\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.7810 - accuracy: 0.5855 - val_loss: 0.8771 - val_accuracy: 0.5704\n",
      "Epoch 5/30\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.7669 - accuracy: 0.5911 - val_loss: 0.9169 - val_accuracy: 0.5532\n",
      "Epoch 6/30\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.7539 - accuracy: 0.5934 - val_loss: 0.8446 - val_accuracy: 0.5916\n",
      "Epoch 7/30\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.7416 - accuracy: 0.5945 - val_loss: 0.8128 - val_accuracy: 0.6201\n",
      "Epoch 8/30\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.7320 - accuracy: 0.5986 - val_loss: 0.8492 - val_accuracy: 0.5792\n",
      "Epoch 9/30\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.7188 - accuracy: 0.6026 - val_loss: 0.8402 - val_accuracy: 0.5923\n",
      "Epoch 10/30\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.7143 - accuracy: 0.6031 - val_loss: 0.8696 - val_accuracy: 0.5762\n",
      "Epoch 11/30\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.7013 - accuracy: 0.6082 - val_loss: 0.8635 - val_accuracy: 0.5887\n",
      "Epoch 12/30\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.7004 - accuracy: 0.6101 - val_loss: 0.9357 - val_accuracy: 0.5484\n",
      "Epoch 13/30\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.6894 - accuracy: 0.6129 - val_loss: 0.8456 - val_accuracy: 0.5931\n",
      "Epoch 14/30\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.6838 - accuracy: 0.6158 - val_loss: 0.9015 - val_accuracy: 0.5484\n",
      "Epoch 15/30\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.6711 - accuracy: 0.6107 - val_loss: 0.9161 - val_accuracy: 0.5470\n",
      "Epoch 16/30\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.6649 - accuracy: 0.6227 - val_loss: 0.8296 - val_accuracy: 0.6073\n",
      "Epoch 17/30\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.6589 - accuracy: 0.6178 - val_loss: 0.8756 - val_accuracy: 0.5740\n",
      "Epoch 18/30\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.6469 - accuracy: 0.6249 - val_loss: 0.8585 - val_accuracy: 0.5876\n",
      "Epoch 19/30\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.6435 - accuracy: 0.6272 - val_loss: 0.8548 - val_accuracy: 0.5901\n",
      "Epoch 20/30\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.6379 - accuracy: 0.6290 - val_loss: 0.9492 - val_accuracy: 0.5327\n",
      "Epoch 21/30\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.6387 - accuracy: 0.6266 - val_loss: 0.8896 - val_accuracy: 0.5660\n",
      "Epoch 22/30\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.6285 - accuracy: 0.6386 - val_loss: 0.8721 - val_accuracy: 0.5806\n",
      "Epoch 23/30\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.6253 - accuracy: 0.6420 - val_loss: 0.8936 - val_accuracy: 0.5726\n",
      "Epoch 24/30\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.6126 - accuracy: 0.6493 - val_loss: 0.8934 - val_accuracy: 0.5634\n",
      "Epoch 25/30\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.6106 - accuracy: 0.6354 - val_loss: 0.8927 - val_accuracy: 0.5803\n",
      "Epoch 26/30\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.6054 - accuracy: 0.6445 - val_loss: 0.9121 - val_accuracy: 0.5609\n",
      "Epoch 27/30\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.6047 - accuracy: 0.6509 - val_loss: 0.9123 - val_accuracy: 0.5824\n",
      "Epoch 28/30\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.5954 - accuracy: 0.6549 - val_loss: 0.9195 - val_accuracy: 0.5711\n",
      "Epoch 29/30\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.5874 - accuracy: 0.6572 - val_loss: 0.9059 - val_accuracy: 0.5890\n",
      "Epoch 30/30\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5888 - accuracy: 0.6555 - val_loss: 0.9484 - val_accuracy: 0.5620\n"
     ]
    }
   ],
   "source": [
    "history = best_model.fit(X_train, y_train_encoded,\n",
    "                         validation_data=(X_val, y_val_encoded),\n",
    "                         class_weight=class_weights,\n",
    "                         epochs=30,\n",
    "                         batch_size=32,\n",
    "                         verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba = best_model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_proba, axis=1) + 1  # Convert back to original labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.66\n",
      "Testing Data Score: 0.55\n"
     ]
    }
   ],
   "source": [
    "train_score = best_model.evaluate(X_train, y_train_encoded, verbose=0)\n",
    "test_score = best_model.evaluate(X_test, y_test_encoded, verbose=0)\n",
    "print(f\"Training Data Score: {train_score[1]:.2f}\")\n",
    "print(f\"Testing Data Score: {test_score[1]:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Observation:*\n",
    "- The Neural Network model performs worse on the testing set than the training set, suggesting there may be some overfitting during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.30      0.65      0.41       292\n",
      "           2       0.84      0.50      0.63      1916\n",
      "           3       0.36      0.65      0.46       528\n",
      "\n",
      "    accuracy                           0.55      2736\n",
      "   macro avg       0.50      0.60      0.50      2736\n",
      "weighted avg       0.69      0.55      0.57      2736\n",
      "\n",
      "Balanced Accuracy: 0.60\n"
     ]
    }
   ],
   "source": [
    "# Evaluation scores\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "balanced_acc = balanced_accuracy_score(y_test, y_pred)\n",
    "print(f\"Balanced Accuracy: {balanced_acc:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Conclusion:**\n",
    "- This 5th model performs worse than the 3rd model across the scores. \n",
    "- The 3rd model is the optimal one so far.\n",
    "\n",
    "---\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DSI_participant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
