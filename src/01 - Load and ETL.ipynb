{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<center>\n",
    "\n",
    "# **I - DATA COLLECTION / ELT** \n",
    "By: Jay Menarco.\n",
    "\n",
    "</center>\n",
    "\n",
    "**PRELIMINARY STEP: GITHUB REPOSITORY SETUP:**\n",
    "\n",
    "- Github repository: jays-codes/team24\n",
    "- Description: Main branch, developent branch, and release branch. \n",
    "- Each team member forks the repository (all branches), and worked (push/pull changes) on the development branch.\n",
    "\n",
    "**DATA COLLECTION / ETL**\n",
    "\n",
    "- Perform ETL (Extract, Load, Transform): \n",
    "    - Extract the following dataset, saved to SQLite database and Github repo: \n",
    "        - TTC Streetcar Delay, FY2023 and YTD-09-2024 (https://open.toronto.ca/dataset/ttc-streetcar-delay-data/): directly extracted to Github. \n",
    "    \n",
    "    - Create the following datasets, save to SQLite database and/or Python dataframes and Github repository:  \n",
    "        - Ontario Public Holiday, 2023 and 2024 (https://excelnotes.com/holidays-ontario-2023/ and https://excelnotes.com/holidays-ontario-2024): no file available, only information online. We manually created the datasets in .csv and saved to Github. \n",
    "        - Line route (https://www.ttc.ca/routes-and-schedules/listroutes/streetcar): no file available, only information online. We manually created the datasets in .csv and saved to Github.  \n",
    "    \n",
    "    - Load: \n",
    "        - Load the data to SQLite database \n",
    "        - From SQLite database, load to Python Panda dataframe. \n",
    "   \n",
    "    - Transform: \n",
    "        - Join datasets to prepare for analysis: \n",
    "        - Perform some feature-engineering to prepare for analysis \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries for this notebook: \n",
    "\n",
    "# Read from SQLite database and load to a pandas dataframe\n",
    "import os\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# For using arrays \n",
    "import numpy as np\n",
    "\n",
    "# For ML work (data preprocessing, hyperparameter tuning, Random Forest Classifier, training & testing sets, and stratified sampling)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# For model evaluation, including explainability:  \n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "import statsmodels.api as sm\n",
    "import shap\n",
    "\n",
    "# For data visualization \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.graphics.mosaicplot import mosaic\n",
    "\n",
    "# For saving the model into a pkl file\n",
    "import joblib\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *DATA COLLECTION & ELT*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LOADING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load data from SQLite database\n",
    "def load_from_db(db_name, table_name):\n",
    "    conn = sqlite3.connect(db_name)\n",
    "    query = f'SELECT * FROM {table_name}'\n",
    "    df = pd.read_sql(query, conn)\n",
    "    conn.close()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database path: C:\\Users\\DELL\\OneDrive\\Desktop\\SCHOOL\\team24_ly\\team24_ly\\data\\streetcardelaydb2.db\n"
     ]
    }
   ],
   "source": [
    "# Set working directory to the notebook's directory\n",
    "os.chdir(r\"C:\\Users\\DELL\\OneDrive\\Desktop\\SCHOOL\\team24_ly\\team24_ly\")\n",
    "\n",
    "# Now define your base directory relative to this location\n",
    "base_dir = os.path.abspath(os.path.join(os.getcwd(), 'data'))\n",
    "db_name = os.path.join(base_dir, 'streetcardelaydb2.db')\n",
    "\n",
    "print(f\"Database path: {db_name}\")\n",
    "\n",
    "# Check if the database file exists\n",
    "if not os.path.exists(db_name):\n",
    "    raise FileNotFoundError(f\"Database file not found: {db_name}\")\n",
    "\n",
    "# Load data\n",
    "table_name = 'Streetcar_Delay_Data'\n",
    "df = load_from_db(db_name, table_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TRANSFORMING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>incident_date</th>\n",
       "      <th>line</th>\n",
       "      <th>incident_time</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>location</th>\n",
       "      <th>incident</th>\n",
       "      <th>min_delay</th>\n",
       "      <th>min_gap</th>\n",
       "      <th>bound</th>\n",
       "      <th>vehicle</th>\n",
       "      <th>holidayType</th>\n",
       "      <th>seasonType</th>\n",
       "      <th>lineId</th>\n",
       "      <th>lineName</th>\n",
       "      <th>delayType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>505</td>\n",
       "      <td>02:40</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>BROADVIEW AND GERRARD</td>\n",
       "      <td>Held By</td>\n",
       "      <td>15</td>\n",
       "      <td>25</td>\n",
       "      <td>W</td>\n",
       "      <td>4460</td>\n",
       "      <td>New Year's Day</td>\n",
       "      <td>Winter 2023</td>\n",
       "      <td>505</td>\n",
       "      <td>Dundas</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>504</td>\n",
       "      <td>02:52</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>KING AND BATHURST</td>\n",
       "      <td>Cleaning - Unsanitary</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>W</td>\n",
       "      <td>4427</td>\n",
       "      <td>New Year's Day</td>\n",
       "      <td>Winter 2023</td>\n",
       "      <td>504</td>\n",
       "      <td>King</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>504</td>\n",
       "      <td>02:59</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>KING AND BATHURST</td>\n",
       "      <td>Held By</td>\n",
       "      <td>25</td>\n",
       "      <td>35</td>\n",
       "      <td>E</td>\n",
       "      <td>4560</td>\n",
       "      <td>New Year's Day</td>\n",
       "      <td>Winter 2023</td>\n",
       "      <td>504</td>\n",
       "      <td>King</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>510</td>\n",
       "      <td>05:38</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>SPADINA AND DUNDAS</td>\n",
       "      <td>Security</td>\n",
       "      <td>15</td>\n",
       "      <td>30</td>\n",
       "      <td>S</td>\n",
       "      <td>4449</td>\n",
       "      <td>New Year's Day</td>\n",
       "      <td>Winter 2023</td>\n",
       "      <td>510</td>\n",
       "      <td>Spadina</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>506</td>\n",
       "      <td>06:35</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>OSSINGTON STATION</td>\n",
       "      <td>Security</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>None</td>\n",
       "      <td>8706</td>\n",
       "      <td>New Year's Day</td>\n",
       "      <td>Winter 2023</td>\n",
       "      <td>506</td>\n",
       "      <td>Carlton</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  incident_date line incident_time day_of_week               location  \\\n",
       "0    2023-01-01  505         02:40      Sunday  BROADVIEW AND GERRARD   \n",
       "1    2023-01-01  504         02:52      Sunday      KING AND BATHURST   \n",
       "2    2023-01-01  504         02:59      Sunday      KING AND BATHURST   \n",
       "3    2023-01-01  510         05:38      Sunday     SPADINA AND DUNDAS   \n",
       "4    2023-01-01  506         06:35      Sunday      OSSINGTON STATION   \n",
       "\n",
       "                incident  min_delay  min_gap bound vehicle     holidayType  \\\n",
       "0                Held By         15       25     W    4460  New Year's Day   \n",
       "1  Cleaning - Unsanitary         10       20     W    4427  New Year's Day   \n",
       "2                Held By         25       35     E    4560  New Year's Day   \n",
       "3               Security         15       30     S    4449  New Year's Day   \n",
       "4               Security         10       20  None    8706  New Year's Day   \n",
       "\n",
       "    seasonType lineId lineName  delayType  \n",
       "0  Winter 2023    505   Dundas          2  \n",
       "1  Winter 2023    504     King          2  \n",
       "2  Winter 2023    504     King          3  \n",
       "3  Winter 2023    510  Spadina          2  \n",
       "4  Winter 2023    506  Carlton          2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert incident_date to datetime format\n",
    "df['incident_date'] = pd.to_datetime(df['incident_date'])\n",
    "\n",
    "# Load Date table to get holidayType columns\n",
    "date_table_name = 'Date'\n",
    "conn = sqlite3.connect(db_name)\n",
    "date_df = pd.read_sql_query(f'SELECT * FROM {date_table_name}', conn)\n",
    "date_df['date'] = pd.to_datetime(date_df['date'])\n",
    "\n",
    "# Merge Date table with Streetcar_Delay_Data table on incident_date\n",
    "df = df.merge(date_df[['date', 'holidayType']], left_on='incident_date', right_on='date', how='left')\n",
    "df.drop(columns=['date'], inplace=True)\n",
    "\n",
    "# Load Season table to get seasonType column\n",
    "season_table_name = 'Season'\n",
    "season_df = pd.read_sql_query(f'SELECT * FROM {season_table_name}', conn)\n",
    "season_df['date'] = pd.to_datetime(season_df['date'])\n",
    "\n",
    "# Merge Season table with Streetcar_Delay_Data table on incident_date\n",
    "df = df.merge(season_df[['date', 'season']], left_on='incident_date', right_on='date', how='left')\n",
    "df.rename(columns={'season': 'seasonType'}, inplace=True)\n",
    "df.drop(columns=['date'], inplace=True)\n",
    "\n",
    "# Load Line table to get lineId and lineName (no lineType)\n",
    "line_table_name = 'Line'\n",
    "line_df = pd.read_sql_query(f'SELECT * FROM {line_table_name}', conn)\n",
    "\n",
    "# Merge the dataframes on lineId\n",
    "df = df.merge(line_df[['lineId', 'lineName']], left_on='line', right_on='lineId', how='left')\n",
    "\n",
    "# Load Delay table to get delayType\n",
    "delay_table_name = 'Delay'\n",
    "delay_df = pd.read_sql_query(f'SELECT * FROM {delay_table_name}', conn)\n",
    "\n",
    "# Function to determine delayType\n",
    "def get_delay_type(min_delay):\n",
    "    for _, row in delay_df.iterrows():\n",
    "        if row['delayFrom'] <= min_delay <= row['delayTo']:\n",
    "            return row['delayId']\n",
    "    return None\n",
    "\n",
    "# Apply the function to determine delayType\n",
    "df['delayType'] = df['min_delay'].apply(get_delay_type)\n",
    "\n",
    "# Close the database connection\n",
    "conn.close()\n",
    "\n",
    "# Display the DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save df as \"df_prelim\" parquet file in 'data' folder\n",
    "relative_path = os.path.join(\"data\", \"df_prelim.parquet\")\n",
    "df.to_parquet(relative_path, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DSI_participant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
